{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381f1f40-86ce-45b0-89af-14a3cccfb6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b3a849-9b00-4fa2-8082-0e71cf3ddeca",
   "metadata": {},
   "source": [
    "Diabetic retinopathy, a complication associated with diabetes, affects the eys and can lead to blindness if not diagnosed. This condition rsults from damage to the blood vessels inside the retina. Diabetic retinopathy is a leading cause of blindness among adults.\\n\",\r\n",
    "    \"\\n\",\r\n",
    "    \"The goal of this project is to implement a machine learning model that can accurately predict the presence of diabetic retinopathy using retinal images.We will be using the [diabetic retinopathy](https://www.kaggle.com/datasets/tanlikesmath/diabetic-retinopathy-resized/) dataset from kaggle, consisting of over 35,000 1024x1024 retinal scans. Below is an example of an individual retinal scan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34da6837-1414-4794-ab5a-6ecf26bc56d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(path):\n",
    "\n",
    "    \"\"\" Plot a provided image \"\"\"\n",
    "    img = Image.open(path)\n",
    "    \n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "plot_image('./dataset/resized_train_cropped/34035_right.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a856b53-9f3b-4dc2-8159-dbb1a8a78323",
   "metadata": {},
   "source": [
    "We begin by preprocessing all images in the dataset. Normalization involves converting the each .jpeg file into an $m \\times n$ array. The `normalize() function converts the elements of the array into 16 bit float point variables between the value of 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982a6e96-e7c2-4108-bb7b-f1d7a5753c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(path):\n",
    "\n",
    "    \"\"\" Normalize an image by resizing and scaling pixel values \"\"\"\n",
    "\n",
    "    # resize 1024x1024 image to 512x512\n",
    "    img = Image.open(path).resize((512, 512))\n",
    "\n",
    "    # set values as float16 between 0 and 1\n",
    "    array = np.array(img).astype(np.float16) / 255.0\n",
    "\n",
    "    return array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ac8442-30b8-451e-8070-b8f2ffbc1e00",
   "metadata": {},
   "source": [
    "The function below uses a `ImageDataGenerator` to augment a single image per call to `augment()`. The goal of augmentation is to artificially increase diversity in a training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af677895-47c7-44aa-b58e-95609743df58",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,       # rotate image\n",
    "    width_shift_range=0.2,   # shift width \n",
    "    height_shift_range=0.2,  # shift height \n",
    "    shear_range=0.2,         # shear image\n",
    "    zoom_range=0.2,          # zoom in or out\n",
    "    horizontal_flip=True,    # flip horizontal?\n",
    "    fill_mode='nearest'      # fill new pixels\n",
    ")\n",
    "\n",
    "def augment(array):\n",
    "\n",
    "    \"\"\" Augment image using ImageImageDataGenerator \"\"\"\n",
    "\n",
    "    # add dimension for IDG\n",
    "    img = np.expand_dims(array, 0)\n",
    "\n",
    "    # create iterator to perform augmentation\n",
    "    it = datagen.flow(img, batch_size = 1)\n",
    "\n",
    "    # retrieve image and conver to desired datatype\n",
    "    augmented = next(it)[0].astype(np.float16)\n",
    "\n",
    "    return augmented"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd58d00-12e7-46f0-8922-a2dfdfd80aca",
   "metadata": {},
   "source": [
    "The `process()` function just calls `augment()` and `normalize()` functions and returns an exception if anything is wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7441944-5ad7-44b7-8c2d-9d1d2e9ad7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(path):\n",
    "\n",
    "    \"\"\" Process singular image given path \"\"\"\n",
    "\n",
    "    try:\n",
    "        # normalize and augment image\n",
    "        array = normalize(path)\n",
    "        array = augment(array)\n",
    "\n",
    "        return array\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b63529-4612-48be-ba73-59dd4dc232cc",
   "metadata": {},
   "source": [
    "Below we load image data from a csv file, clean it to remove unecessary columns, and then prepare a dataset by appending the full path to each image - `image` column is added to list of images as `./dataset/image.jpeg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d80d28c-7945-4cb3-b7de-635522819eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_csv_path = './dataset/trainLabels_cropped.csv'\n",
    "labels_df = pd.read_csv(labels_csv_path)\n",
    "\n",
    "# remove useless columns\n",
    "labels_df = labels_df.drop(columns=['Unnamed: 0.1', 'Unnamed: 0'])\n",
    "\n",
    "# define image directory\n",
    "image_dir = './dataset/resized_train_cropped/'\n",
    "\n",
    "# append path and extension to each image name\n",
    "labels_df['full_image_path'] = image_dir + labels_df['image'] + '.jpeg'\n",
    "\n",
    "# split into training and validation (80% and 20% respectively)\n",
    "train_indices, val_indices = train_test_split(labels_df.index, test_size=0.2, random_state=42)\n",
    "\n",
    "# generate all image paths\n",
    "train_image_paths = [labels_df.iloc[i]['full_image_path'] for i in train_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac08e9a-baea-484c-bbf0-2065900a1e78",
   "metadata": {},
   "source": [
    "The `load_data_gen` function is a generator that loads and processes images in batches from the provided paths from above. It pairs each image with its corresponding label and then creates label and image numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04d276c-40ba-49a8-8fcd-a09675cc1a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_gen(image_paths, labels_df, batch_size=32):\n",
    "    \n",
    "    \"\"\" Generator to load and process data in batches \"\"\"\n",
    "    # total num of images\n",
    "    num_samples = len(image_paths)\n",
    "    \n",
    "    while True: # loop while next image is True\n",
    "        \n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            \n",
    "            batch_images = [] # images in current batch\n",
    "            batch_labels = [] # labels in current batch\n",
    "\n",
    "            # iterate over batch\n",
    "            for i in range(offset, min(offset + batch_size, num_samples)):\n",
    "                \n",
    "                path = image_paths[i] # get path of current image\n",
    "                img = process(path)   # process current image\n",
    "\n",
    "                # if image processing was successful, add to batch\n",
    "                if img is not None:\n",
    "                    batch_images.append(img)\n",
    "                    # get label for current image\n",
    "                    label = labels_df.iloc[i]['level']\n",
    "                    batch_labels.append(label)\n",
    "\n",
    "            # convert list of images and labels to numpy arrays\n",
    "            batch_images_np = np.array(batch_images)\n",
    "            batch_labels_np = np.array(batch_labels)\n",
    "            \n",
    "            # return images and labels \n",
    "            yield batch_images_np, batch_labels_np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b230a25b-86d8-4a99-bb43-5770ea109296",
   "metadata": {},
   "source": [
    "We define a convolutional neural network for 512x512 pixel images with three color channels. The network uses convolutional layers to reduce the image dimensions, followed by flattening the multi-dimensional array into a one-dimensional array. This is then processed through dense layers, integrating the learned features, with a dropout layer included to help prevent overfitting. The network concludes with a final dense layer that outputs a probability score, indicating the classification of the image. The model is compiled with the Adam optimizer and binary cross-entropy loss, focusing on accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79abb4a-b105-42f0-bc7b-c102219a5b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(512, 512, 3)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343c0735-2bd1-47c9-8421-94b7d2733666",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_generator = load_data_gen(train_image_paths, labels_df, batch_size=batch_size)\n",
    "\n",
    "# calculate num of steps per epoch\n",
    "steps_per_epoch = len(train_indices) // batch_size\n",
    "\n",
    "# start fitting the model using the training generator\n",
    "model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67acad8b-af17-40c1-9cfe-9cbf54656a7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
